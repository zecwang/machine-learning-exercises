{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "### Qualitative Features & Interaction Terms\n",
    "\n",
    "#### 1-A) Use the credit data set, fit OLS linear regression model to predict credit card balance using all the following features\n",
    " - Student\n",
    " - Income\n",
    " - Limit\n",
    " - Interaction term: Income*Student\n",
    " - Interaction term: Limit*Student\n",
    "\n",
    "Find the p-values of all features. Are they all helpful in predicting the response? Why? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept              -415.3863     12.436    -33.401      0.000    -439.836    -390.936\n",
      "Student[T.Yes]          235.2261     41.256      5.702      0.000     154.117     316.336\n",
      "Income                   -7.6162      0.252    -30.272      0.000      -8.111      -7.122\n",
      "Income:Student[T.Yes]    -2.5835      0.702     -3.678      0.000      -3.965      -1.202\n",
      "Limit                     0.2613      0.004     69.090      0.000       0.254       0.269\n",
      "Limit:Student[T.Yes]      0.0667      0.012      5.515      0.000       0.043       0.090\n",
      "=========================================================================================\n",
      "Intercept                5.549684e-117\n",
      "Student[T.Yes]            2.330768e-08\n",
      "Income                   7.366425e-105\n",
      "Income:Student[T.Yes]     2.680862e-04\n",
      "Limit                    2.626683e-222\n",
      "Limit:Student[T.Yes]      6.320226e-08\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "from pandas import read_csv\n",
    "\n",
    "credit =read_csv('Credit2.csv')\n",
    "\n",
    "\n",
    "model=smf.ols('Balance ~ Student+Income+Income*Student+Limit +Limit*Student', credit)\n",
    "Fitting_results=model.fit()\n",
    "\n",
    "print(Fitting_results.summary().tables[1])\n",
    "print(Fitting_results.pvalues)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All features have low p-value, and hence we'd expect that they are important in predicting the response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-B) Find the test $R^2$ score for estimating the balance from features (Income, Limit, StudentEncode) using linear regression model. The StudentEncode is the binary feature that maps Student status to a numerical value ('yes' to 1 and 'No' to 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0   Income  Limit  Rating  Cards  Age  Education  Gender Student  \\\n",
      "0           1   14.891   3606     283      2   34         11    Male      No   \n",
      "1           2  106.025   6645     483      3   82         15  Female     Yes   \n",
      "2           3  104.593   7075     514      4   71         11    Male      No   \n",
      "3           4  148.924   9504     681      3   36         11  Female      No   \n",
      "4           5   55.882   4897     357      2   68         16    Male      No   \n",
      "\n",
      "  Married  Ethnicity  Balance  StudentEncode  \n",
      "0     Yes  Caucasian      333              0  \n",
      "1     Yes      Asian      903              1  \n",
      "2      No      Asian      580              0  \n",
      "3      No      Asian      964              0  \n",
      "4     Yes  Caucasian      331              0  \n",
      "The test R^2 score by predicting balance using student status and income 0.949269175529\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "credit =read_csv('Credit2.csv')\n",
    "credit['StudentEncode'] = credit.Student.map({'No':0 , 'Yes':1}) \n",
    "print(credit.head(5))\n",
    "\n",
    "X = credit[[ 'StudentEncode','Income','Limit']]\n",
    "Y = credit.Balance\n",
    "\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(X, Y, random_state= 0)\n",
    "linreg= LinearRegression().fit(X_train, Y_train)\n",
    "\n",
    "print('The test R^2 score by predicting balance using student status and income', linreg.score(X_test,Y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-C) Repeat the above question after adding to the model the two interaction terms: (1) (Income x StudentEncode) and (2) (Limit x StudentEncode)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 score by predicting balance using student status and income 0.952585323631\n"
     ]
    }
   ],
   "source": [
    "credit['InteractionTerm1']=credit.Income*credit.StudentEncode\n",
    "credit['InteractionTerm2']=credit.Limit*credit.StudentEncode\n",
    "\n",
    "X = credit[[ 'StudentEncode','Income','Limit', 'InteractionTerm1','InteractionTerm2']]\n",
    "Y = credit.Balance\n",
    "\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(X, Y, random_state= 0)\n",
    "linreg= LinearRegression().fit(X_train, Y_train)\n",
    "\n",
    "print('R^2 score by predicting balance using student status and income', linreg.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### comment: Interaction terms have strong association with response as they have low p-values, and including them improved the performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Polynomial Regression\n",
    "\n",
    "#### 2-A) Use the Auto dataset, find the test $R^2$ score of a linear regression model that predicts the miles per gallon (mpg) from the horsepower.\n",
    "\n",
    "#### 2-B) Use polynomial regression to include both the horsepower feature and $(horsepower)^2$ in the regression model. Find the $R^2$ metric. \n",
    "\n",
    "Hint: You can use [numpy.concatenate](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.concatenate.html). For example to add to an array U a column vector $W^2$, we can use X=np.concatenate((U,W**2),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(392, 9)\n",
      "With polynomial of degree 1 the R squared score of linear regression is: 0.62176588114\n",
      "With polynomial of degree 2 the R squared score of linear regression is: 0.727103150464\n"
     ]
    }
   ],
   "source": [
    "#Solution for (A) and (B)\n",
    "from pandas import read_csv\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "AutoData=read_csv('Auto_modify.csv') # read the data\n",
    "print(type(AutoData))\n",
    "print(AutoData.shape)\n",
    "X_auto_hp=AutoData.horsepower.values.reshape(-1,1) # define features: horsepower \n",
    "Y_auto_mpg=AutoData.mpg.values.reshape(-1,1) # define label: miles per gallon\n",
    "\n",
    "modelAuto2=LinearRegression()\n",
    "\n",
    "X=X_auto_hp\n",
    "for power in [1,2]:\n",
    "    if power>1:\n",
    "        X=np.concatenate((X,X_auto_hp**power),axis=1)\n",
    "        \n",
    "    X_train, X_test, Y_train, Y_test= train_test_split(X, Y_auto_mpg, random_state= 0)\n",
    "    Auto_fitted_model2=modelAuto2.fit(X_train,Y_train)\n",
    "    R2_auto_hp=Auto_fitted_model2.score(X_test,Y_test)\n",
    "    print('With polynomial of degree', power, 'the R squared score of linear regression is:', R2_auto_hp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C) With the same auto dataset, use KNN regression with K=7, to fit a model that predicts miles per gallon(mpg) in the following cases:\n",
    "\n",
    "- One feature: Horsepower only\n",
    "\n",
    "- Two features: horsepower and $(horsepower)^2$ \n",
    "\n",
    "#### Use MinMax feaures scaling. Find the $R^2$ metric in each of the above cases. Comparing KNN with linear regression, which model performs better? How does the performance change by adding the quadratic feature?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Including feature of hoursepower to the power of 1 , R squared score of KNN regression is 0.660924983306\n",
      "Including feature of hoursepower to the power of 2 , R squared score of KNN regression is 0.670108404882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# add you code here \n",
    "\n",
    "knnRegression = neighbors.KNeighborsRegressor(n_neighbors=7)\n",
    "X=X_auto_hp\n",
    "for power in [1,2]:\n",
    "    if power>1:\n",
    "        X=np.concatenate((X,X_auto_hp**power),axis=1)\n",
    "        \n",
    "    X_train, X_test, Y_train, Y_test= train_test_split(X, Y_auto_mpg, random_state= 0)\n",
    "    \n",
    "    scaler=preprocessing.MinMaxScaler().fit(X_train)\n",
    "    X_train_transformed=scaler.transform(X_train)\n",
    "    X_test_transformed=scaler.transform(X_test)\n",
    "    \n",
    "    Auto_fitted_model2=knnRegression.fit(X_train_transformed,Y_train)\n",
    "    R2_auto_hp=knnRegression.score(X_test_transformed,Y_test)\n",
    "    print(\"Including feature of hoursepower to the power of\", power, \", R squared score of KNN regression is\", R2_auto_hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments:\n",
    "\n",
    "- KNN performs better that linear regression with a single feature (horsepower)\n",
    "- Linear regression performs better than KNN when the non-linear terms are added.. Since the actual model is almost quadratic, parametric method with a quatratic term performs better (linear regression performs better by adding the quadratic term)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
